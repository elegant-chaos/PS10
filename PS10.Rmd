---
title: "STAT/MATH 495: Problem Set 10"
author: "Jenn Halbleib"
date: "2017-11-28"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE)
```



# Collaboration

Please indicate who you collaborated with on this assignment: 



# Setup

```{r}
library(tidyverse)
library(broom)
library(glmnet)
library(MLmetrics)
get_LASSO_coefficients <- function(LASSO_fit){
  coeff_values <- LASSO_fit %>% 
    broom::tidy() %>% 
    as_tibble() %>% 
    select(-c(step, dev.ratio)) %>% 
    tidyr::complete(lambda, nesting(term), fill = list(estimate = 0)) %>% 
    arrange(desc(lambda)) %>% 
    select(term, estimate, lambda)
  return(coeff_values)
}

train <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")

# Only use 150 observations to train model!
set.seed(76)
train_subset <- train %>% 
  mutate(log_price_doc = log(price_doc)) %>% 
  sample_n(150)

# Need "dummy" outcome variable to make model.matrix() code below work
test <- test %>% 
  mutate(log_price_doc=1) 

# Model formula
model_formula <- as.formula("log_price_doc ~ full_sq + area_m + raion_popul + green_zone_part + indust_part + children_preschool + preschool_education_centers_raion + children_school + school_education_centers_raion + school_education_centers_top_20_raion + healthcare_centers_raion + university_top_20_raion + sport_objects_raion + additional_education_raion + culture_objects_top_25 + culture_objects_top_25_raion + shopping_centers_raion + office_raion + thermal_power_plant_raion + incineration_raion + oil_chemistry_raion + radiation_raion + railroad_terminal_raion + big_market_raion + nuclear_reactor_raion + detention_facility_raion + full_all + male_f + female_f + young_all + young_male + young_female + work_all + work_male + work_female + ekder_all + ekder_male + ekder_female + ID_metro + metro_min_avto + metro_km_avto + kindergarten_km + school_km + park_km + green_zone_km + industrial_km + water_treatment_km + cemetery_km + incineration_km + railroad_station_avto_km + railroad_station_avto_min + ID_railroad_station_avto + public_transport_station_km + public_transport_station_min_walk + water_km + water_1line + mkad_km + ttk_km + sadovoe_km + bulvar_ring_km + kremlin_km + big_road1_km + ID_big_road1 + big_road1_1line + big_road2_km + ID_big_road2 + railroad_km + railroad_1line + zd_vokzaly_avto_km + ID_railroad_terminal + bus_terminal_avto_km + ID_bus_terminal + oil_chemistry_km + nuclear_reactor_km + radiation_km + power_transmission_line_km + thermal_power_plant_km + ts_km + big_market_km + market_shop_km + fitness_km + swim_pool_km + ice_rink_km + stadium_km + basketball_km + hospice_morgue_km + detention_facility_km + public_healthcare_km + university_km + workplaces_km + shopping_centers_km + office_km + additional_education_km + preschool_km + big_church_km + church_synagogue_km + mosque_km + theater_km + museum_km + exhibition_km + catering_km + green_part_500 + prom_part_500 + office_count_500 + office_sqm_500 + trc_count_500 + trc_sqm_500") 

# Define predictor matrices
predictor_matrix_train <- model.matrix(model_formula, data = train_subset)[, -1]
predictor_matrix_test <- model.matrix(model_formula, data = test)[, -1]
```


# Do work and create submission files:

```{r}
#Visualizing the outcome variable
ggplot(data = train, aes(train$price_doc)) + geom_histogram() + xlab("Sale Price")
#Since the data is skewed, looking at log(price_doc)
ggplot(data = train, aes(log(train$price_doc))) + geom_histogram() + xlab("Log Sale Price")
#Will use log(price_doc) since distribution is more normal

#Find lambda star using test set to predict log(price_doc)
LASSO_CV <- cv.glmnet(x=predictor_matrix_train, y=train_subset$log_price_doc, alpha=1)
#Set optimal lambda
lambda_star_1SE <- LASSO_CV$lambda.1se
#Making predictions
y_hat_log <- predict(LASSO_CV, newx=predictor_matrix_test, s=lambda_star_1SE) 
#Sanity check: Does the distribution of predictions match the distribution in the training data?
ggplot() + aes(y_hat_log) + geom_histogram()
#Looks at least reasonable, so pressing forward with this set of predictions

#Convert back to original units
y_hat <- exp(y_hat_log)

#Make submission df
submission <- cbind(as.integer(test$id), as.integer(y_hat))
colnames(submission) <- c("id", "price_doc")
submission <- as.data.frame(submission)

#Write submission to .csv
write_csv(submission, "submission.csv")
```



# Scoreboard

```{r}
#Predictions from LASSO on the training data
y_hat_train <- predict(LASSO_CV, newx=predictor_matrix_train, s=lambda_star_1SE)
lasso_rmsle <- RMSLE(exp(y_hat_train), train_subset$price_doc)
lasso_rmsle

#Predictions from lm on the training data
lm_train <- predict(LASSO_CV, newx=predictor_matrix_train, s = 0)
lm_rmsle <- RMSLE(exp(lm_train), train_subset$price_doc)
lm_rmsle

#Making a submission file for lm
lm_y_hat_log <- predict(LASSO_CV, newx=predictor_matrix_test, s=0)
#Convert back to original units
lm_y_hat <- exp(lm_y_hat_log)

#Make submission df
submission2 <- cbind(as.integer(test$id), as.integer(lm_y_hat))
colnames(submission2) <- c("id", "price_doc")
submission2 <- as.data.frame(submission2)

#Write submission to .csv
write_csv(submission2, "submission2.csv")
```


Using the "scoring mechanism" for the Russian Housing Kaggle competition, fill
in these cells:


Method                | Training Score  | Kaggle Score
--------------------- | -------------   | -------------
lm                    |  0.2791267      | 0.90662 
LASSO crossvalidated  |  0.5477483      | 0.45879
